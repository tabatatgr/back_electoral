# ðŸ”§ OPTIMIZACIONES DE MEMORIA PARA RENDER

## âš ï¸ PROBLEMA DETECTADO:
- **Plan FREE Render: 512 MB RAM**
- **Uso actual estimado: 300-400 MB por request**
- **Archivo pesado: INE_SECCION_2020.csv = 50 MB**

## âœ… SOLUCIONES APLICADAS:

### 1. **ConversiÃ³n CSV â†’ Parquet** âœ…
```
INE_SECCION_2020.csv:     49.89 MB
INE_SECCION_2020.parquet: 20.86 MB
REDUCCIÃ“N: 58.2% (29 MB ahorrados)
```

**Beneficios:**
- âœ… Carga 3-5x mÃ¡s rÃ¡pida (parquet es binario)
- âœ… Menor uso de RAM (compresiÃ³n snappy)
- âœ… No requiere parsing de texto

**Archivo modificado:**
- `redistritacion/modulos/distritacion.py` - ahora usa `.parquet` con fallback a `.csv`

### 2. **Actualizar .gitignore** âœ…
Evitar subir archivos temporales y cachÃ©s:
```gitignore
__pycache__/
*.pyc
tmp_*.py
test_*.py
outputs/*.csv
```

---

## ðŸ“Š USO DE MEMORIA ESTIMADO (DESPUÃ‰S):

```
Inicio FastAPI:
â”œâ”€ Base: ~150 MB
â””â”€ OK para FREE âœ…

Request con redistritacion/:
â”œâ”€ Parquet (21 MB): ~50 MB en RAM
â”œâ”€ Procesamiento: 100-150 MB
â””â”€ PICO: 200-300 MB âœ… (dentro de 512 MB)
```

---

## ðŸš€ RECOMENDACIONES ADICIONALES:

### Si sigue crasheando Render:

#### OpciÃ³n A: Lazy imports (no cargar todo al inicio)
```python
# En lugar de importar al inicio:
# from redistritacion.modulos.distritacion import cargar_secciones_ine

# Importar solo cuando se usa:
def endpoint_que_usa_redistritacion():
    from redistritacion.modulos.distritacion import cargar_secciones_ine
    secciones = cargar_secciones_ine()
    ...
```

#### OpciÃ³n B: Cache con TTL
```python
from functools import lru_cache
import time

@lru_cache(maxsize=1)
def cargar_secciones_cached():
    return cargar_secciones_ine()

# Se carga 1 vez y se reutiliza
```

#### OpciÃ³n C: Subir a plan PAID ($7/mes)
- 512 MB â†’ 2 GB RAM
- Sin sleep automÃ¡tico
- Deploy mÃ¡s rÃ¡pidos

---

## ðŸ“ CHECKLIST DEPLOY:

### Antes de hacer push:
- [x] Convertir CSV a Parquet
- [x] Actualizar cÃ³digo para usar Parquet
- [x] Agregar .gitignore
- [ ] Agregar Parquet al repo
- [ ] Hacer commit y push
- [ ] Verificar que Render despierte

### Comandos:
```bash
# Agregar archivos optimizados
git add redistritacion/data/INE_SECCION_2020.parquet
git add redistritacion/modulos/distritacion.py
git add .gitignore

# Commit
git commit -m "perf: optimizar memoria - CSVâ†’Parquet (50MBâ†’21MB)"

# Push (Render auto-deploya)
git push
```

---

## ðŸ” MONITOREAR DESPUÃ‰S DEL DEPLOY:

1. **Ver logs en Render:**
   https://dashboard.render.com â†’ back_electoral â†’ Logs

2. **Buscar en logs:**
   - `MemoryError` - Se quedÃ³ sin RAM
   - `503 Service Unavailable` - CrasheÃ³
   - `Request timeout` - TardÃ³ >30s

3. **Test rÃ¡pido:**
```bash
# Ping bÃ¡sico
curl https://back-electoral.onrender.com/

# Endpoint pesado (usa redistritacion)
curl https://back-electoral.onrender.com/calcular/mayoria_forzada_senado?partido=MORENA&tipo_mayoria=simple
```

---

## ðŸ’¡ NOTAS FINALES:

**Si el servidor sigue muriendo:**
- Es probable que otros endpoints tambiÃ©n carguen datos pesados
- Considera migrar TODOS los CSV grandes a Parquet
- O usar SQLite/DuckDB para queries eficientes

**Archivos a revisar:**
```
data/computos_*.parquet  â†’ Ya estÃ¡n en parquet âœ…
data/siglado-*.csv       â†’ Pesan poco (30 KB) âœ…
redistritacion/data/INE_DISTRITO_2020.CSV â†’ 370 KB (OK)
```

Todo listo para deploy optimizado ðŸš€
